{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb1KYydZ_27J"
      },
      "source": [
        "# Bird Sound Recognize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNyofQOUACfX"
      },
      "source": [
        "### Prepare Package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b6Aw7jPFbzs"
      },
      "source": [
        "## Value Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfvbyEIV-3hx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pickle\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUjNWHMQ_vOg"
      },
      "source": [
        "### Mount at Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCCeVN168Fhk"
      },
      "outputs": [],
      "source": [
        "RUN_ONLINE = False\n",
        "if RUN_ONLINE:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "    PREFIX = Path(\"Gdrive path here\")\n",
        "else:\n",
        "    PREFIX = Path(\"Local path here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G51hD67_pPy"
      },
      "source": [
        "### Train Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_F3-OSI98cN"
      },
      "outputs": [],
      "source": [
        "SOUND_PATH = str(PREFIX / \"dataset/raw\")\n",
        "DATASET_PATH = str(PREFIX / \"dataset/Tyler_data\")\n",
        "WAV_PATH = r\"\"\n",
        "\n",
        "MODEL_NAME = \"Model_test\"\n",
        "\n",
        "TIME_STEP = 20\n",
        "SOUND_LENGTH = 128\n",
        "TEST_DATA_RATIO = 0.3\n",
        "INPUT_SHAPE = (TIME_STEP, SOUND_LENGTH)\n",
        "CLASSES = [\n",
        "    \"before_net\",\n",
        "    \"build_nest\",\n",
        "    \"fail\",\n",
        "    \"hug_egg\",\n",
        "    \"out_nest\",\n",
        "    \"spawn\",\n",
        "    \"yu_zhu_qi\",\n",
        "]\n",
        "\n",
        "MODEL_CONV1DS = [256, 0, 256]\n",
        "MODEL_LAYERS_POW = [8, 7, 8, 9, 8]\n",
        "MODEL_LAYERS = [512, 0, 128, 0, 64, 16]\n",
        "BATCH_SIZE = 60\n",
        "EPOCHS = 100\n",
        "\n",
        "model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_maL2k9Ev6F"
      },
      "source": [
        "## Prepare All Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BI0wNrk_oQp"
      },
      "source": [
        "### Sound Proccess Tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Numpy_Gaussian_noise(inputs, stdev):\n",
        "    noise = stdev * np.random.normal(size = inputs.shape) \n",
        "    return inputs + noise"
      ],
      "metadata": {
        "id": "sZWdtavBLJ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m57p0yPR_Hvv"
      },
      "outputs": [],
      "source": [
        "class SoundProcessor:\n",
        "    def __init__(self):\n",
        "        self.data = []\n",
        "        self.sr = None\n",
        "\n",
        "    def load_sound(self, path):\n",
        "        self.data, self.sr = librosa.load(path)\n",
        "        return self.data\n",
        "\n",
        "    def transform_mfcc(self, data):\n",
        "        mfcc = librosa.feature.mfcc(y=data, sr=self.sr, n_mfcc=SOUND_LENGTH)\n",
        "        arr = mfcc.T #分貝\n",
        "        arr = arr[np.shape(arr)[0] % TIME_STEP:, :]\n",
        "        return arr\n",
        "\n",
        "    def plot_mfcc(self, data, save_path):\n",
        "        arr = librosa.feature.mfcc(y=data, sr=self.sr, dct_type=3)\n",
        "        arr = arr.T\n",
        "        mfccArr = arr[np.shape(arr)[0] % TIME_STEP:, :]\n",
        "        count = 0\n",
        "        if mfccArr.shape[0] < TIME_STEP:\n",
        "            print(\"Arr is too short, ignored.\", mfccArr.shape)\n",
        "            return\n",
        "        for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP):\n",
        "            count += 1\n",
        "            fig, ax = plt.subplots()\n",
        "            img = librosa.display.specshow(subArr, ax=ax)\n",
        "            fig.colorbar(img, ax=ax)\n",
        "            fig.savefig(save_path[:-4] + f\"_{count}.png\")\n",
        "            fig.clear()\n",
        "\n",
        "    def bird_sound_all_classes_json(self, load_folder, save_path):\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "        for folder in os.listdir(load_folder):\n",
        "            load_path = os.path.join(load_folder, folder)\n",
        "            folderData = []\n",
        "            for filename in os.listdir(load_path):\n",
        "                if 'hack' in filename:\n",
        "                    continue\n",
        "                data = self.load_sound(os.path.join(load_path, filename))\n",
        "                mfccArr = self.transform_mfcc(data)\n",
        "                if mfccArr.shape[0] < TIME_STEP:\n",
        "                    print(filename, \"arr is too short, ignored.\", mfccArr.shape)\n",
        "                    continue\n",
        "                for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP):\n",
        "                    # print(\"test\")\n",
        "                    # print(len(subArr[0]))\n",
        "                    folderData.append(subArr.tolist())\n",
        "                print(filename, \" done.\")\n",
        "            split_idx = max(1, int(len(folderData) * TEST_DATA_RATIO))\n",
        "            random.seed(8787)\n",
        "            random.shuffle(folderData)\n",
        "            test_arr = folderData[:split_idx]\n",
        "            train_arr = folderData[split_idx:]\n",
        "            # print(test_arr)\n",
        "            # print(train_arr)\n",
        "            filename = os.path.join(save_path, folder + \".json\")\n",
        "            with open(filename, \"w\") as f:\n",
        "                print(np.array(test_arr).shape)\n",
        "                print(np.array(train_arr).shape)\n",
        "                data = {\"test\": test_arr, \"train\": train_arr}\n",
        "                json.dump(data, f)\n",
        "            print(folder + \".json\", \" saved.  \\n\", \"Located: \", filename)\n",
        "\n",
        "        print(\"Every folder have done!\")\n",
        "        print(f\"Save at path: {save_path}\")\n",
        "        print(\"==================================================================================================\")\n",
        "\n",
        "    def bird_sound_all_classes_npy(self, load_folder, save_path):\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "        for folder in os.listdir(load_folder):\n",
        "            load_path = os.path.join(load_folder, folder)\n",
        "            folderData = []\n",
        "            for filename in os.listdir(os.path.join(load_path)):\n",
        "                data = self.load_sound(os.path.join(load_path, filename))\n",
        "                mfccArr = self.transform_mfcc(data)\n",
        "                if mfccArr.shape[0] < TIME_STEP:\n",
        "                    print(filename, \"arr is too short, ignored.\", mfccArr.shape)\n",
        "                    continue\n",
        "                for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP):\n",
        "                    folderData.append(subArr)\n",
        "                print(filename, \" done.\")\n",
        "            split_idx = max(1, int(len(folderData) * TEST_DATA_RATIO))\n",
        "            test_arr = folderData[:split_idx]\n",
        "            train_arr = folderData[split_idx:]\n",
        "            random.shuffle(folderData)\n",
        "            test_npy_folder = os.path.join(save_path, \"test\")\n",
        "            train_npy_folder = os.path.join(save_path, \"train\")\n",
        "            if not os.path.exists(test_npy_folder):\n",
        "                os.mkdir(test_npy_folder)\n",
        "            if not os.path.exists(train_npy_folder):\n",
        "                os.mkdir(train_npy_folder)\n",
        "            test_npy_filename = os.path.join(test_npy_folder, folder + \".npy\")\n",
        "            train_npy_filename = os.path.join(train_npy_folder, folder + \".npy\")\n",
        "            np.save(test_npy_filename, np.asarray(test_arr))\n",
        "            # print(test_arr)\n",
        "            np.save(train_npy_filename, np.asarray(train_arr))\n",
        "            print(test_npy_filename, \"saved. length:\", TIME_STEP, \" x \", SOUND_LENGTH)\n",
        "            print(train_npy_filename, \"saved. length:\", TIME_STEP, \" x \", SOUND_LENGTH)\n",
        "\n",
        "        print(\"Every folder have done!\")\n",
        "        print(f\"Save at path: {save_path}\")\n",
        "        print(\"==================================================================================================\")\n",
        "\n",
        "    def hack_load_wav_into_json(self, load_folder, save_path):\n",
        "        global now_hacking\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "        for c in now_hacking:\n",
        "            folder = CLASSES[c]\n",
        "            load_path = os.path.join(load_folder, folder)\n",
        "            folderData = []\n",
        "            for filename in os.listdir(load_path):\n",
        "                if 'hack' in filename:\n",
        "                    continue\n",
        "                data = self.load_sound(os.path.join(load_path, filename))\n",
        "                mfccArr = self.transform_mfcc(data)\n",
        "                if mfccArr.shape[0] < TIME_STEP:\n",
        "                    print(filename, \"arr is too short, ignored.\", mfccArr.shape)\n",
        "                    continue\n",
        "                for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP):\n",
        "                    # print(\"test\")\n",
        "                    # print(len(subArr[0]))\n",
        "                    folderData.append(subArr.tolist())\n",
        "                print(filename, \" done.\")\n",
        "            split_idx = max(1, int(len(folderData) * TEST_DATA_RATIO))\n",
        "            random.seed(8787)\n",
        "            random.shuffle(folderData)\n",
        "            test_arr = folderData[:split_idx]\n",
        "            train_arr = folderData[split_idx:]\n",
        "            # print(test_arr)\n",
        "            # print(train_arr)\n",
        "            filename = os.path.join(save_path, folder + \".json\")\n",
        "            with open(filename, \"w\") as f:\n",
        "                print(np.array(test_arr).shape)\n",
        "                print(np.array(train_arr).shape)\n",
        "                data = {\"test\": test_arr, \"train\": train_arr}\n",
        "                json.dump(data, f)\n",
        "    def instant_transform(self, data):\n",
        "        mfccArr = self.transform_mfcc(data)\n",
        "        if mfccArr.shape[0] < TIME_STEP:\n",
        "            print(\"Video is too short, can't recognize.\")\n",
        "            return np.array([])\n",
        "        queue = [subArr for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP)]\n",
        "        return np.array(queue)\n",
        "\n",
        "    def load_json(self, load_folder):\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "        y=0\n",
        "        for y, c in enumerate(CLASSES):\n",
        "            filename = c+'.json'\n",
        "            assert os.path.exists(os.path.join(load_folder, \"JSON\", filename)), f'{os.path.join(load_folder, \"JSON\", filename)} doesn\\'t exist'\n",
        "            print(f'loading {filename}')\n",
        "            load_path = os.path.join(load_folder, \"JSON\", filename)\n",
        "            print(load_path)\n",
        "            data = json.load(open(load_path))\n",
        "            print(f\"{filename} have loaded.\")\n",
        "            x_test += data[\"test\"]\n",
        "            x_train += data[\"train\"]\n",
        "            for i in range(len(data[\"test\"])):\n",
        "                y_test.append(y)\n",
        "            for i in range(len(data[\"train\"])):\n",
        "                y_train.append(y)\n",
        "            y+=1\n",
        "        return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
        "    def hack_load_json(self, load_folder):\n",
        "        global now_hacking\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "        y=0\n",
        "        for c in now_hacking:\n",
        "            filename = f\"{CLASSES[c]}.json\"\n",
        "            path = Path(load_folder)/filename\n",
        "            if not os.path.isfile(os.path.join(load_folder, filename)):\n",
        "              continue\n",
        "            print(f'loading {filename}')\n",
        "            load_path = os.path.join(load_folder, filename)\n",
        "            print(load_path)\n",
        "            data = json.load(open(load_path))\n",
        "            print(f\"{filename} have loaded.\")\n",
        "            x_test += data[\"test\"]\n",
        "            x_test += data[\"train\"]\n",
        "            for i in range(len(data[\"test\"])):\n",
        "                y_test.append(y)\n",
        "            for i in range(len(data[\"train\"])):\n",
        "                y_test.append(y)\n",
        "            y+=1\n",
        "        return np.array(x_test), np.array(y_test)\n",
        "    def load_npy(self, load_folder):\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "        for y, filename in enumerate(os.listdir(os.path.join(load_folder, \"NPY\", \"train\"))):\n",
        "            load_path = os.path.join(load_folder, \"NPY\", \"train\", filename)\n",
        "            print(load_path)\n",
        "            data = np.load(load_path, allow_pickle=True)\n",
        "            print(f\"{filename} have loaded, shape: \", data.shape)\n",
        "            x_train += data.tolist()\n",
        "            for i in range(data.shape[0]):\n",
        "                y_train.append(y)\n",
        "\n",
        "        for y, filename in enumerate(os.listdir(os.path.join(load_folder, \"NPY\", \"test\"))):\n",
        "            load_path = os.path.join(load_folder, \"NPY\", \"test\", filename)\n",
        "            print(load_path)\n",
        "            data = np.load(load_path, allow_pickle=True)\n",
        "            print(f\"{filename} have loaded, shape: \", data.shape)\n",
        "            x_test += data.tolist()\n",
        "            for i in range(data.shape[0]):\n",
        "                y_test.append(y)\n",
        "        return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
        "\n",
        "\n",
        "    def plot_bird_sound_all_classes(self, load_folder, save_path):\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "        for folder in os.listdir(load_folder):\n",
        "            if not os.path.exists(os.path.join(save_path, folder)):\n",
        "                os.mkdir(os.path.join(save_path, folder))\n",
        "            load_path = os.path.join(load_folder, folder)\n",
        "            for filename in os.listdir(os.path.join(load_path)):\n",
        "                path = os.path.join(save_path, folder, filename)\n",
        "                data = self.load_sound(os.path.join(load_path, filename))\n",
        "                self.plot_mfcc(data, path)\n",
        "                print(folder + \".json\", \" have plot.  \\n\", \"Located: \", path)\n",
        "\n",
        "        print(\"Every figure have done!\")\n",
        "        print(f\"Save at path: {save_path}\")\n",
        "        print(\"==================================================================================================\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Y61psuATWf"
      },
      "source": [
        "### Model Create Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGyKf7jpCClq"
      },
      "source": [
        "#### Classes TransForm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKUL7dmeCLKM"
      },
      "outputs": [],
      "source": [
        "def classes_change(mode):\n",
        "    for i, C in enumerate(CLASSES):\n",
        "        if i == mode:\n",
        "            return C\n",
        "    return \"None\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvKm6rLvCa2U"
      },
      "source": [
        "#### Model Basic Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBplA1UvByKj"
      },
      "outputs": [],
      "source": [
        "def setting(model):\n",
        "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def fit(model, x_train, y_train, x_test, y_test, batch, epochs):\n",
        "    y_train = to_categorical(y_train, 7)\n",
        "    y_test = to_categorical(y_test, 7)\n",
        "    print(\"START TRAINING==================================================================\")\n",
        "    train_history = model.fit(x=x_train, y=y_train,\n",
        "                  validation_split=0.2,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch,\n",
        "                  verbose=2,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  shuffle=True,\n",
        "                  )\n",
        "    return model, train_history\n",
        "\n",
        "def save(model, save_path, name):\n",
        "    if not os.path.exists(save_path):\n",
        "        os.mkdir(save_path)\n",
        "    model.save(os.path.join(save_path, name+\".h5\"))\n",
        "    print(\"Model have saved.\")\n",
        "\n",
        "def load(save_path):\n",
        "    model = keras.models.load_model(save_path+\".h5\")\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFYV1NgAnEy"
      },
      "source": [
        "#### Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUXeDAHRWww"
      },
      "source": [
        "##### Conv1D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKuevYE0ASWi"
      },
      "outputs": [],
      "source": [
        "def createConv1DModel(\n",
        "        name,\n",
        "        n_conv1Ds,\n",
        "        n_layers,\n",
        "        d_input,\n",
        "        n_classes):\n",
        "    \"\"\"\n",
        "    @param name: model name\n",
        "    @param n_conv1Ds: filters of conv1D\n",
        "    @param n_layers: filters of dense\n",
        "    @param d_input: input shape\n",
        "    @param n_classes: output classes\n",
        "    @return: model\n",
        "    \"\"\"\n",
        "    '''\n",
        "    MODEL_CONV1DS = [256, 0, 256]\n",
        "    MODEL_LAYERS = [512, 0, 128, 0, 64, 16]\n",
        "    '''\n",
        "    model = Sequential(name=f\"{name}\")\n",
        "    model.add(Conv1D(128, kernel_size=3, input_shape=d_input, activation=\"relu\", data_format = 'channels_first'))\n",
        "    model.add(MaxPool1D(pool_size=2, data_format = 'channels_first'))\n",
        "    for i in n_conv1Ds[1:]: #[C, M, D, C, M, / FC, D, FC, D, FC, FC/, FC]\n",
        "        if i == 0:\n",
        "            model.add(Dropout(0.2))\n",
        "        else:\n",
        "            model.add(Conv1D(i, kernel_size=3, activation=\"relu\", data_format = 'channels_first'))\n",
        "            model.add(MaxPool1D(pool_size=2, data_format = 'channels_first'))\n",
        "    model.add(Flatten())\n",
        "    for i in n_layers:\n",
        "        if i == 0:\n",
        "            model.add(Dropout(0.2))\n",
        "        else:\n",
        "            model.add(Dense(i, activation=\"relu\"))\n",
        "    model.add(Dense(len(n_classes), activation=None))\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8q62NpDwEMZ"
      },
      "source": [
        "#### Get model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJM-m-BeAuOx"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    return createConv1DModel(\"model\",\n",
        "                  MODEL_CONV1DS,\n",
        "                  MODEL_LAYERS,\n",
        "                  INPUT_SHAPE,\n",
        "                  CLASSES,\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8q1CHHgCijl"
      },
      "source": [
        "#### Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjBmatBZCaD9"
      },
      "outputs": [],
      "source": [
        "def predict_classes(model, data):\n",
        "    prediction = [np.argmax(arr) for arr in model.predict(data)]\n",
        "    predict_class = [classes_change(arr) for arr in prediction]\n",
        "    return prediction, predict_class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5ElplMCqSi"
      },
      "source": [
        "#### Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEfQ9QW0CuML"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test(model, x_test, y_test, test_time=10):\n",
        "    success = 0\n",
        "    predictions, classes = predict_classes(model, x_test)\n",
        "    for i in range(test_time):\n",
        "        index = random.randint(0, len(x_test))\n",
        "        predict = predictions[index]\n",
        "        print(f\"test{i+1}\\t| prediction: \", classes[index], \"\\n     \\t| answer: \", classes_change(y_test[index]))\n",
        "        if predict == y_test[index]:\n",
        "            print(f\"Match\\t| [ O ]\")\n",
        "            success += 1\n",
        "        else:\n",
        "            print(f\"Match\\t| [ X ]\")\n",
        "    print(\"Accuracy: \", success/test_time*100, \"%.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejs3UQaYCwzT"
      },
      "source": [
        "#### Plot Model's Accuracy & Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRjzMpL7GOlv"
      },
      "outputs": [],
      "source": [
        "def load_history(load_path, name):\n",
        "    with open(os.path.join(load_path, name+\"_history.p\"), 'rb') as f:\n",
        "        history = pickle.load(f)\n",
        "    print(\"History have loaded\")\n",
        "    return history\n",
        "\n",
        "\n",
        "def save_history(history, save_path, name):\n",
        "  history = history.history\n",
        "  if not os.path.exists(save_path):\n",
        "    os.mkdir(save_path)\n",
        "  with open(os.path.join(save_path, name+\"_history.p\"), 'wb') as f:\n",
        "      pickle.dump(history, f)\n",
        "  print(\"History have saved\")\n",
        "\n",
        "\n",
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name, is_save=True, save_path=\"\"):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation\n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "\n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "    # Plot the Graph.\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label=metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label=metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    if not os.path.exists(save_path) and is_save:\n",
        "      os.mkdir(save_path)\n",
        "\n",
        "    if is_save and save_path != \"\":\n",
        "      fig.savefig(save_path+\".png\")\n",
        "\n",
        "def plot_all(model_training_history):\n",
        "  plot_metric(model_training_history, \"loss\", \"val_loss\", \"Train Loss Vs Train Val Loss\",\n",
        "        True, os.path.join(DATASET_PATH, \"MODEL\", MODEL_NAME + \"_loss\"))\n",
        "  plot_metric(model_training_history, \"accuracy\", \"val_accuracy\", \"Train Acc Vs Train Val Acc\",\n",
        "        True, os.path.join(DATASET_PATH, \"MODEL\", MODEL_NAME + \"_acc\"))\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP8YOTJkC3pg"
      },
      "outputs": [],
      "source": [
        "def plot(history, save_path, name):\n",
        "    if not os.path.exists(save_path):\n",
        "        os.mkdir(save_path)\n",
        "    print(history.history.keys())\n",
        "    fig = plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    fig.savefig(os.path.join(save_path, f\"{name}_accuracy.png\"))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    fig.savefig(os.path.join(save_path, f\"{name}_loss.png\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSvMNw-kDHM4"
      },
      "source": [
        "### Main wav proccess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usq-B7XTDFZN"
      },
      "outputs": [],
      "source": [
        "def main_wav_process(mode):\n",
        "    soundTool = SoundProcessor()\n",
        "    if mode == \"npy\":\n",
        "        soundTool.bird_sound_all_classes_npy(SOUND_PATH, os.path.join(DATASET_PATH, \"NPY\"))\n",
        "    elif mode == \"json\":\n",
        "        soundTool.bird_sound_all_classes_json(SOUND_PATH, os.path.join(DATASET_PATH, \"JSON\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlrMTpFfDhDc"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC_MLKEKDZ-W"
      },
      "outputs": [],
      "source": [
        "def data_loader(mode, path=DATASET_PATH):\n",
        "    soundTool = SoundProcessor()\n",
        "    x_train, y_train, x_test, y_test = [None]*4\n",
        "    if mode == \"npy\":\n",
        "        x_train, y_train, x_test, y_test = soundTool.load_npy(path)\n",
        "    elif mode == \"json\":\n",
        "        x_train, y_train, x_test, y_test = soundTool.load_json(path)\n",
        "    elif mode == \"hack\":\n",
        "        x_test, y_test = soundTool.hack_load_json(path)\n",
        "    else:\n",
        "        print(\"Please choice data type.\")\n",
        "        return\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLTTuIPTDtu8"
      },
      "source": [
        "### Main Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw4fKN07Dk_f"
      },
      "outputs": [],
      "source": [
        "def main_training(x_train, y_train, x_test, y_test, modelname):\n",
        "    print(\"x_train: \", x_train.shape)\n",
        "    print(\"y_train: \", y_train.shape)\n",
        "    print(\"x_test: \", x_test.shape)\n",
        "    print(\"y_test: \", y_test.shape)\n",
        "    model = get_model()\n",
        "    model = setting(model)\n",
        "    model, history = fit(model,\n",
        "                x_train, y_train,\n",
        "                x_test, y_test,\n",
        "                BATCH_SIZE,\n",
        "                EPOCHS,\n",
        "                )\n",
        "    save(model, os.path.join(DATASET_PATH, \"MODEL\"), modelname)\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhrw-Y4TN72y"
      },
      "source": [
        "### Main Plot\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT36R8d4OAi_"
      },
      "outputs": [],
      "source": [
        "def main_plot(history):\n",
        "    plot_all(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyp8rx5otDzx"
      },
      "outputs": [],
      "source": [
        "def main_confusion(x_test, y_test):\n",
        "  y_predict = model.predict(x_test)\n",
        "  y_pred = y_predict.argmax(axis=-1)\n",
        "  one_hot_y_test = to_categorical(y_test)\n",
        "  y_true = one_hot_y_test.argmax(axis=-1)\n",
        "  target_names = CLASSES\n",
        "  fig = plt.figure(figsize=(15, 15), dpi=100)\n",
        "  cnf_martrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  plot_confusion_matrix(cnf_martrix, classes=target_names, normalize=True,\n",
        "                      title=\"bird sound recognize confusion matrix\")\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{DATASET_PATH}/FIGURE/confusion_matrix_{MODEL_NAME}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da_OKLmtEJYW"
      },
      "source": [
        "### Main Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy10_szZDyra"
      },
      "outputs": [],
      "source": [
        "def main_testing(x_test, y_test):\n",
        "    model = load(os.path.join(DATASET_PATH, \"MODEL\", MODEL_NAME))\n",
        "    test(model, x_test, y_test, 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd7mvkx0Ef14"
      },
      "source": [
        "### Main Test wav\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfUw2ynJEUMb"
      },
      "outputs": [],
      "source": [
        "def main_test_wav(wav_path):\n",
        "    model = load(os.path.join(DATASET_PATH, \"MODEL\", MODEL_NAME))\n",
        "    soundTool = SoundProcessor()\n",
        "    data = soundTool.load_sound(wav_path)\n",
        "    mfccData = soundTool.instant_transform(data)\n",
        "    if mfccData.shape[0] != np.array([]).shape[0]:\n",
        "        predictions, classes = predict_classes(model, mfccData)\n",
        "        print(\"Prediction: \", max(classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7paXdKs-weS"
      },
      "source": [
        "### Main Get MFCC figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPNsJFxR-wF9"
      },
      "outputs": [],
      "source": [
        "def main_mfcc_figure():\n",
        "  soundTool = SoundProcessor()\n",
        "  soundTool.plot_bird_sound_all_classes(SOUND_PATH, os.path.join(DATASET_PATH, \"FIGURE\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SujaDOnLEqeB"
      },
      "source": [
        "## RUN PLACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw7h2jH5Lk8-"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = data_loader(\"json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiryUlXYEpkB"
      },
      "outputs": [],
      "source": [
        "min_loss = 100000000\n",
        "max_acc = 0\n",
        "each_epoch_loss = []\n",
        "each_epoch_acc = []\n",
        "best_loss_epoch = 0\n",
        "best_acc_epoch = 0\n",
        "for i in range(30, 31):\n",
        "    EPOCHS = i\n",
        "    model, history = main_training(x_train, y_train, x_test, y_test, MODEL_NAME)\n",
        "    min_loss = min(min_loss, history.history[\"val_loss\"][-1])\n",
        "    max_acc = max(max_acc, history.history[\"val_accuracy\"][-1])\n",
        "    if min_loss == history.history[\"val_loss\"][-1]:\n",
        "        best_loss_epoch = i\n",
        "    if max_acc == history.history[\"val_accuracy\"][-1]:\n",
        "        best_acc_epoch = i\n",
        "    each_epoch_loss.append(history.history['val_loss'][-1])\n",
        "    each_epoch_acc.append(history.history[\"val_accuracy\"][-1])\n",
        "\n",
        "print(f\"\\n\\nThe minest loss is {min_loss} \\t| It is at epoch {best_loss_epoch}\")\n",
        "print(f\"The maxest acc is {max_acc} \\t| It is at epoch {best_acc_epoch}\")\n",
        "print()\n",
        "print(each_epoch_loss)\n",
        "print(each_epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svTIR4f1Tb6P"
      },
      "outputs": [],
      "source": [
        "save_history(history, os.path.join(DATASET_PATH, \"HISTORY\"), MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zQrfP1QRmKw"
      },
      "outputs": [],
      "source": [
        "main_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbSg1TEeLsdX"
      },
      "outputs": [],
      "source": [
        "main_testing(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTKll2oSnvyU"
      },
      "outputs": [],
      "source": [
        "main_confusion(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hack\n",
        "\n",
        "目前加入的雜訊是平均值0標準差0.00005的常態分布資料到音檔裡，用audacity測量出大約是-85.88分貝，雖然沒有根據人類聽覺特別設計過雜訊，但還是幾乎沒有辦法分辨\n",
        "\n",
        "在7個類別中，有五個類別在加了雜訊後"
      ],
      "metadata": {
        "id": "ECfLL5GMJ1Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL_FROM_FILE = True\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "  model = load(str(PREFIX/'dataset/Tyler_data/MODEL/Model_test'))#### you may want to change it\n",
        "else:\n",
        "  assert model != None"
      ],
      "metadata": {
        "id": "WRBCogsGau6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d097c670-5ba5-4e9e-df71-b8decd2a7911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-07 20:49:23.303212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.339449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.339658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.340168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-07 20:49:23.340753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.340934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.341075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.804677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.804940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.805196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 20:49:23.805373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2964 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_14 (Conv1D)          (None, 128, 126)          7808      \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 128, 63)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 128, 63)           0         \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 256, 61)           98560     \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 256, 30)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 7680)              0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 512)               3932672   \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 7)                 119       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,114,119\n",
            "Trainable params: 4,114,119\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hack edit wav\n",
        "def Gaussian_noise_layer(inputs, std):\n",
        "  noise = std * tf.random.normal(shape = inputs.get_shape(), mean = 0.0, stddev = 1, dtype = tf.float32) \n",
        "  return inputs + noise\n",
        "def hack_wav(load_path:Path):\n",
        "  for filename in load_path.glob(\"*.wav\"):\n",
        "    filename=str(filename)\n",
        "    if 'hack' in filename:\n",
        "      continue\n",
        "    print(f'opening {filename}')\n",
        "    audio_file = tf.io.read_file(filename)\n",
        "    wave, sr = tf.audio.decode_wav(audio_file)\n",
        "    wave = Gaussian_noise_layer(wave, 0.00005)\n",
        "    audio_file = tf.audio.encode_wav(wave, sr)\n",
        "    tf.io.write_file(filename.replace('.wav','-hack.wav'), audio_file)"
      ],
      "metadata": {
        "id": "XQcHLyXyHWYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hack_check(model, reload_wav, now_hacking):\n",
        "  soundTool = SoundProcessor()\n",
        "  if reload_wav:\n",
        "    soundTool.hack_load_wav_into_json(SOUND_PATH, os.path.join(DATASET_PATH, \"hack\"))\n",
        "  local_x_train, local_y_train, local_x_test, local_y_test = data_loader(\"hack\", str(PREFIX/'dataset/Tyler_data/hack'))\n",
        "  local_x_test = np.reshape(local_x_test, (-1, SOUND_LENGTH))\n",
        "  local_x_test = local_x_test[5:]\n",
        "  local_x_test = local_x_test[:local_x_test.shape[0]//TIME_STEP*TIME_STEP]\n",
        "  local_x_test = np.reshape(local_x_test, (-1, TIME_STEP, SOUND_LENGTH))\n",
        "  res = model.predict(local_x_test)\n",
        "  print('res example:', res[:5])\n",
        "  res = res[:,now_hacking]\n",
        "  min = np.min(res)\n",
        "  print(f'min precent: {min}')\n",
        "  if min<0.1:\n",
        "    return res, True\n",
        "  else:\n",
        "    print('ok, so sad')\n",
        "    return res, False"
      ],
      "metadata": {
        "id": "xvMUDdKvDOP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hack_hist(hist, title, save_path=None):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    bin_size=5\n",
        "    ax.hist(hist, bins=range(0, 100+bin_size, bin_size))\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Number of data')\n",
        "    plt.xlabel('Accuracy (%)')\n",
        "    plt.xlim(xmin=-10., xmax = 110.)\n",
        "    plt.show()\n",
        "    if save_path!=None:\n",
        "      fig.savefig(str(save_path))"
      ],
      "metadata": {
        "id": "H93cA83taSZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hack(reproduce_wav=False, reload_wav=True):\n",
        "  global model, now_hacking\n",
        "  for c in class_to_hack:\n",
        "    now_hacking=[c]\n",
        "    if reproduce_wav:\n",
        "      hack_wav(PREFIX/f'dataset/raw/{CLASSES[c]}')\n",
        "    res, end = hack_check(model, reload_wav, c)\n",
        "    res *= 100\n",
        "    plot_hack_hist(res, CLASSES[c], PREFIX/f\"hack_result/{CLASSES[c]}.jpg\")\n",
        "\n",
        "class_to_hack = [2]\n",
        "hack(True, True)"
      ],
      "metadata": {
        "id": "SrRSr7jJQXHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with any file"
      ],
      "metadata": {
        "id": "uzBIZ8xfS1jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_selected_files(path, files, expected_class):\n",
        "  for f in files:\n",
        "    p=str(path/f)\n",
        "    soundTool = SoundProcessor()\n",
        "    data = soundTool.load_sound(p)\n",
        "    mfccArr = soundTool.transform_mfcc(data)\n",
        "    if mfccArr.shape[0] < TIME_STEP:\n",
        "        print(p, \"arr is too short, ignored.\", mfccArr.shape)\n",
        "        continue\n",
        "    mfccArr = mfccArr[(np.random.choice(TIME_STEP)):]\n",
        "    mfccArr = mfccArr[:mfccArr.shape[0] // TIME_STEP * TIME_STEP]\n",
        "    global model\n",
        "    test_data = []\n",
        "    for subArr in np.split(mfccArr, mfccArr.shape[0] // TIME_STEP):\n",
        "      test_data.append(subArr)\n",
        "    test_data = np.array(test_data)\n",
        "    res = model(test_data)\n",
        "    print(res)\n",
        "    res = res[:, expected_class]\n",
        "    print(res)\n",
        "    res *=100\n",
        "    plot_hack_hist(res, f)"
      ],
      "metadata": {
        "id": "w5u86ZZgS59S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read wav file and test"
      ],
      "metadata": {
        "id": "y84q0RUPZTY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_with_selected_files(PREFIX/f'dataset/raw/{CLASSES[2]}', ['0001.wav', '0001-hack.wav'], 2)"
      ],
      "metadata": {
        "id": "h1g9Xsq4cnWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## demo optimizer.minimize"
      ],
      "metadata": {
        "id": "HLulH1KGua4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "a = tf.Variable(tf.zeros((5), tf.float32))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "def f_a():\n",
        "  return tf.reduce_sum((a-1)**2)\n",
        "for i in range(400):\n",
        "  opt.minimize(f_a, [a])\n",
        "  print(i, a.numpy())"
      ],
      "metadata": {
        "id": "d04BM8Ovit5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試噪音聽感\n"
      ],
      "metadata": {
        "id": "MhQREjcurOXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std = 5e-5\n",
        "file = tf.audio.encode_wav(tf.random.normal((44100*100,1), stddev=std), 44100)\n",
        "tf.io.write_file(str(PREFIX/f'noise{std}.wav'), file)"
      ],
      "metadata": {
        "id": "nUQZWRRrnGDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## add unperceivable noise to audio and see difference of mfcc result"
      ],
      "metadata": {
        "id": "zjgOtkNmuK6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p=str(PREFIX/f'dataset/raw/{CLASSES[0]}/0000.wav')\n",
        "soundTool = SoundProcessor()\n",
        "data = soundTool.load_sound(p)\n",
        "noised_data = Numpy_Gaussian_noise(data, 5e-5)\n",
        "mfccArr = soundTool.transform_mfcc(data)\n",
        "noised_mfccArr = soundTool.transform_mfcc(noised_data)\n",
        "diff = np.reshape(abs(noised_mfccArr-mfccArr), (-1))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.hist(diff, bins=1000)\n",
        "plt.xlim(xmin=-0.5, xmax = 2)\n",
        "plt.show()\n",
        "\n",
        "print(f'mid: {np.median(diff)}')\n",
        "print(f'min: {np.min(diff)}')\n",
        "print(f'max: {np.max(diff)}')\n",
        "print(f'mean: {np.mean(diff)}')"
      ],
      "metadata": {
        "id": "jAcKUPw4rdE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decide to limit change to 0.2\n",
        "\n",
        "## hack 2.0"
      ],
      "metadata": {
        "id": "WGqL7S0LuTLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = model(x_test)\n",
        "res = res * to_categorical(y_test, 7)\n",
        "res = tf.reduce_max(res, axis=1)\n",
        "l = tf.argsort(res)\n",
        "print(l[:10])"
      ],
      "metadata": {
        "id": "Of4PLPl-brsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = np.random.choice(1929, (50), False)"
      ],
      "metadata": {
        "id": "qgOQ51oaV9r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_hack(to_hack):\n",
        "  x_hack = x_test[to_hack]\n",
        "  y_hack = to_categorical((y_test[to_hack]+1)%7, 7)\n",
        "  return x_hack, y_hack"
      ],
      "metadata": {
        "id": "_yyo0GtUvXSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Projected Gradient Descent"
      ],
      "metadata": {
        "id": "gCv4QbBfKyZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hist(inputs):\n",
        "  plt.hist(inputs, bins = 100)\n",
        "  plt.show()\n",
        "  print(f'mid: {np.median(inputs)}')\n",
        "  print(f'min: {np.min(inputs)}')\n",
        "  print(f'max: {np.max(inputs)}')\n",
        "  print(f'mean: {np.mean(inputs)}')"
      ],
      "metadata": {
        "id": "9LrR-6n_bttX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hack_result_PGD = []\n",
        "for to_hack in l[:50]:\n",
        "    print(f\"now hacking {to_hack}\")\n",
        "    x_hack, y_hack = choose_hack(to_hack)\n",
        "    noise_to_mfcc_data = tf.Variable(\n",
        "        tf.keras.initializers.GlorotUniform()((1, TIME_STEP, SOUND_LENGTH))\n",
        "    )\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
        "    class tmp:\n",
        "        def __init__(self, v=None):\n",
        "            self.v = v\n",
        "\n",
        "        def set(self, v):\n",
        "            self.v = v\n",
        "\n",
        "    loss_record = tmp()\n",
        "    get_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    def loss_fn():\n",
        "        x_new = x_hack + noise_to_mfcc_data\n",
        "        global model\n",
        "        y_predict = tf.reshape(model(x_new), (-1))\n",
        "        loss = -get_loss(y_hack, y_predict)\n",
        "        loss_record.set(loss)\n",
        "        return loss\n",
        "\n",
        "    constraint = 0.2\n",
        "    last = 1000\n",
        "    for i in range(100):\n",
        "        opt.minimize(loss_fn, [noise_to_mfcc_data])\n",
        "        noise_to_mfcc_data.assign(\n",
        "            tf.clip_by_value(noise_to_mfcc_data, -constraint, constraint)\n",
        "        )\n",
        "        if i % 50 == 0:\n",
        "            res = loss_fn()\n",
        "            print(i, res.numpy())\n",
        "    x_new = x_hack + noise_to_mfcc_data\n",
        "    y_predict = tf.nn.softmax(tf.reshape(model(x_new), (-1)))\n",
        "    print(f\"acc:{y_predict[y_test[to_hack]].numpy()}\")\n",
        "    hack_result_PGD.append(y_predict[y_test[to_hack]].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1eab858-ca4c-4d66-8e64-b7e6367e9557",
        "id": "FOtCMvphrdE9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now hacking 567\n",
            "acc:0.15892121195793152\n",
            "now hacking 1599\n",
            "acc:0.006189380772411823\n",
            "now hacking 1012\n",
            "acc:0.9184435606002808\n",
            "now hacking 918\n",
            "acc:0.9097972512245178\n",
            "now hacking 895\n",
            "acc:0.0003219297796022147\n",
            "now hacking 645\n",
            "acc:0.9441558122634888\n",
            "now hacking 449\n",
            "acc:0.09076428413391113\n",
            "now hacking 516\n",
            "acc:0.05117999017238617\n",
            "now hacking 762\n",
            "acc:0.865360677242279\n",
            "now hacking 1300\n",
            "acc:0.001080856891348958\n",
            "now hacking 923\n",
            "acc:0.23942646384239197\n",
            "now hacking 321\n",
            "acc:0.8133878707885742\n",
            "now hacking 657\n",
            "acc:0.26030075550079346\n",
            "now hacking 250\n",
            "acc:0.15829236805438995\n",
            "now hacking 329\n",
            "acc:0.0005005456623621285\n",
            "now hacking 627\n",
            "acc:0.004438014701008797\n",
            "now hacking 545\n",
            "acc:0.15055407583713531\n",
            "now hacking 266\n",
            "acc:7.404840289382264e-06\n",
            "now hacking 738\n",
            "acc:0.0012403838336467743\n",
            "now hacking 542\n",
            "acc:2.2315637693282042e-07\n",
            "now hacking 535\n",
            "acc:0.7102530598640442\n",
            "now hacking 511\n",
            "acc:0.003999793436378241\n",
            "now hacking 275\n",
            "acc:6.633382554355194e-08\n",
            "now hacking 613\n",
            "acc:0.04614171385765076\n",
            "now hacking 360\n",
            "acc:0.011502058245241642\n",
            "now hacking 741\n",
            "acc:0.02540736086666584\n",
            "now hacking 443\n",
            "acc:0.05774593725800514\n",
            "now hacking 249\n",
            "acc:0.9203912615776062\n",
            "now hacking 384\n",
            "acc:0.0016623858828097582\n",
            "now hacking 245\n",
            "acc:0.9077221155166626\n",
            "now hacking 407\n",
            "acc:0.5315402746200562\n",
            "now hacking 518\n",
            "acc:9.505391790298745e-05\n",
            "now hacking 405\n",
            "acc:0.5023058652877808\n",
            "now hacking 499\n",
            "acc:0.0026701942551881075\n",
            "now hacking 491\n",
            "acc:0.17499591410160065\n",
            "now hacking 242\n",
            "acc:0.009705694392323494\n",
            "now hacking 305\n",
            "acc:2.672003951431634e-08\n",
            "now hacking 306\n",
            "acc:0.003899735864251852\n",
            "now hacking 265\n",
            "acc:0.08182976394891739\n",
            "now hacking 527\n",
            "acc:2.7229345445078934e-09\n",
            "now hacking 631\n",
            "acc:0.8520455360412598\n",
            "now hacking 509\n",
            "acc:4.4739540072669115e-08\n",
            "now hacking 459\n",
            "acc:0.0015116427093744278\n",
            "now hacking 267\n",
            "acc:1.1285832712815136e-08\n",
            "now hacking 494\n",
            "acc:0.9587349891662598\n",
            "now hacking 944\n",
            "acc:0.23105008900165558\n",
            "now hacking 278\n",
            "acc:6.504044414157306e-09\n",
            "now hacking 1575\n",
            "acc:0.008214674890041351\n",
            "now hacking 365\n",
            "acc:3.155439909363622e-09\n",
            "now hacking 921\n",
            "acc:0.000524627510458231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(hack_result_PGD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1f68c1e6-7579-4864-b539-df3b28675d36",
        "id": "Q7NZ36tDl4iX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mid: 0.05151965096592903\n",
            "min: 2.6619913384706706e-08\n",
            "max: 0.9446098804473877\n",
            "mean: 0.2560676038265228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fast Gradient Sign Method"
      ],
      "metadata": {
        "id": "CmLX8heRLAvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hack_result_FGSM = []\n",
        "for to_hack in l[:50]:\n",
        "    x_hack, y_hack = choose_hack(to_hack)\n",
        "    noise_to_mfcc_data = tf.Variable(tf.zeros((1, TIME_STEP, SOUND_LENGTH)), tf.float32)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "    get_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    trainable_variables = [noise_to_mfcc_data]\n",
        "    for _ in range(100):\n",
        "        with tf.GradientTape() as t:\n",
        "            x_new = x_hack + noise_to_mfcc_data\n",
        "            y_predict = tf.reshape(model(x_new), (-1))\n",
        "            loss = get_loss(y_hack, y_predict)\n",
        "\n",
        "        gradients = tf.math.sign(t.gradient(loss, trainable_variables))\n",
        "        opt.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    x_new = x_hack + noise_to_mfcc_data\n",
        "    y_predict = tf.nn.softmax(tf.reshape(model(x_new), (-1)))\n",
        "    print(f\"acc:{y_predict[y_test[to_hack]].numpy()}\")\n",
        "    hack_result_FGSM.append(y_predict[y_test[to_hack]].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxjdzRG8l0l8",
        "outputId": "eb7e11fc-e30b-4e17-bd16-470ed54d8a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:1.0926631821561728e-10\n",
            "acc:0.9995672106742859\n",
            "acc:0.9995779395103455\n",
            "acc:0.9999864101409912\n",
            "acc:0.2574045956134796\n",
            "acc:0.9999021291732788\n",
            "acc:0.9998332262039185\n",
            "acc:0.9998989105224609\n",
            "acc:0.9999665021896362\n",
            "acc:0.9975754618644714\n",
            "acc:0.9999927282333374\n",
            "acc:0.9999959468841553\n",
            "acc:0.9999957084655762\n",
            "acc:0.9999885559082031\n",
            "acc:0.9999957084655762\n",
            "acc:0.9995085000991821\n",
            "acc:0.9999994039535522\n",
            "acc:0.9999997615814209\n",
            "acc:0.9999852180480957\n",
            "acc:1.0\n",
            "acc:0.9999933242797852\n",
            "acc:0.9999997615814209\n",
            "acc:0.9999994039535522\n",
            "acc:0.9999988079071045\n",
            "acc:0.999993085861206\n",
            "acc:0.9999998807907104\n",
            "acc:1.0\n",
            "acc:0.9999788999557495\n",
            "acc:0.9999998807907104\n",
            "acc:0.9999998807907104\n",
            "acc:1.0\n",
            "acc:0.9999821186065674\n",
            "acc:0.9996169805526733\n",
            "acc:0.9999996423721313\n",
            "acc:0.9999998807907104\n",
            "acc:1.0\n",
            "acc:0.9999983310699463\n",
            "acc:0.9999997615814209\n",
            "acc:0.9998201727867126\n",
            "acc:0.9999994039535522\n",
            "acc:1.0\n",
            "acc:1.0\n",
            "acc:0.9999994039535522\n",
            "acc:0.9999998807907104\n",
            "acc:0.9999955892562866\n",
            "acc:0.9999996423721313\n",
            "acc:0.9999860525131226\n",
            "acc:1.0\n",
            "acc:0.9999996423721313\n",
            "acc:0.9999935626983643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(hack_result_FGSM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "L3Is1SK3gWfw",
        "outputId": "ff03d74f-e33b-4b78-8461-3d7616cb5a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mid: 1.0\n",
            "min: 0.22567811608314514\n",
            "max: 1.0\n",
            "mean: 0.964169442653656\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
